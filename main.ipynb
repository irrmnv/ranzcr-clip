{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "import argus\n",
    "from argus.callbacks import MonitorCheckpoint, LoggingToFile, CosineAnnealingLR\n",
    "\n",
    "from src.commons import config, get_best_model_path, seed_everything\n",
    "from src.dataset import get_train_data, get_train_folds, transforms_soft, RANZCRDataset, filter_train_annotated_folds\n",
    "from src.metrics import MultiAUC\n",
    "from src.models import RANZCRStageZero, RANZCRStageOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)\n",
    "\n",
    "train = get_train_data()\n",
    "folds = get_train_folds(train)\n",
    "folds_annotated = filter_train_annotated_folds(train, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RANZCRDataset(train, 'annotated', transform=A.Compose(transforms_soft))\n",
    "\n",
    "plt.imshow(dataset[2][0].transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nn_module': {\n",
    "        'model_name': config.model_name,\n",
    "        'pretrained': True,\n",
    "        'num_classes': config.num_classes,\n",
    "        'in_chans': 1,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'lr': config.lr,\n",
    "    },\n",
    "    'device': 'cuda',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(folds_annotated):\n",
    "    model = RANZCRStageZero(params)\n",
    "    model.set_device((0, 1, 2, 3))\n",
    "\n",
    "    train_dataset, val_dataset = Subset(dataset, train_index), Subset(dataset, test_index)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size, num_workers=config.n_workers, pin_memory=True, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.valid_batch_size, num_workers=config.n_workers, pin_memory=True)\n",
    "\n",
    "    callbacks = [\n",
    "        MonitorCheckpoint(dir_path=f'{config.experiment_name}_stage0_fold_{i}', monitor='val_multi_auc', max_saves=3),\n",
    "        CosineAnnealingLR(T_max=5, eta_min=config.min_lr),\n",
    "        LoggingToFile(f'{config.experiment_name}_stage0_fold_{i}.log'),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=5,\n",
    "        metrics=['loss', 'multi_auc'],\n",
    "        callbacks=callbacks,\n",
    "        metrics_on_train=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RANZCRDataset(train, 'both', transform=A.Compose(transforms_soft, additional_targets={'orig': 'image'}))\n",
    "\n",
    "(orig, img), label = dataset[2]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(orig.transpose(1, 2, 0))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img.transpose(1, 2, 0))\n",
    "plt.title(f'label: {label}')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nn_module': {\n",
    "        'model_name': config.model_name,\n",
    "        'pretrained': True,\n",
    "        'num_classes': config.num_classes,\n",
    "        'in_chans': 1,\n",
    "        'drop_rate': 0.3,\n",
    "        'drop_path_rate': 0.2,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'lr': config.lr,\n",
    "    },\n",
    "    'device': 'cuda',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(folds_annotated):\n",
    "    teacher_model = argus.load_model(get_best_model_path(f'{config.experiment_name}_stage0_fold_{i}/'), device='cpu')\n",
    "    teacher_model.eval()\n",
    "\n",
    "    teacher_model = teacher_model.get_nn_module()\n",
    "\n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    params['nn_module']['teacher_model'] = teacher_model\n",
    "    model = RANZCRStageOne(params)\n",
    "    model.set_device((0, 1, 2, 3))\n",
    "\n",
    "    train_dataset, val_dataset = Subset(dataset, train_index), Subset(dataset, test_index)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size, num_workers=config.n_workers, pin_memory=True, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.valid_batch_size, num_workers=config.n_workers, pin_memory=True)\n",
    "\n",
    "    callbacks = [\n",
    "        MonitorCheckpoint(dir_path=f'{config.experiment_name}_stage1_fold_{i}', monitor='val_multi_auc', max_saves=3),\n",
    "        CosineAnnealingLR(T_max=10, eta_min=config.min_lr),\n",
    "        LoggingToFile(f'{config.experiment_name}_stage1_fold_{i}.log'),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=10,\n",
    "        metrics=['loss', 'multi_auc'],\n",
    "        callbacks=callbacks,\n",
    "        metrics_on_train=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RANZCRDataset(train, 'orig', transform=A.Compose(transforms_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nn_module': {\n",
    "        'model_name': config.model_name,\n",
    "        'pretrained': False,\n",
    "        'num_classes': config.num_classes,\n",
    "        'in_chans': 1,\n",
    "        'drop_rate': 0.3,\n",
    "        'drop_path_rate': 0.2,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'lr': config.lr / 2,\n",
    "    },\n",
    "    'device': 'cuda',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, label = dataset[0]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(orig.transpose(1, 2, 0))\n",
    "plt.title(f'label: {label}')\n",
    "\n",
    "orig, label = dataset[2]\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(orig.transpose(1, 2, 0))\n",
    "plt.title(f'label: {label}')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(folds):\n",
    "    model = torch.load(get_best_model_path(f'{config.experiment_name}_stage1_fold_{i}/'), map_location='cpu')\n",
    "    state_dict = {k.replace('student_model.', ''): v for k, v in model['nn_state_dict'].items() if 'student_model' in k}\n",
    "    if False:\n",
    "        state_dict['fc.weight'] = model['nn_state_dict']['fc.weight']\n",
    "        state_dict['fc.bias'] = model['nn_state_dict']['fc.bias']\n",
    "    else:\n",
    "        state_dict['classifier.weight'] = model['nn_state_dict']['fc.weight']\n",
    "        state_dict['classifier.bias'] = model['nn_state_dict']['fc.bias']\n",
    "\n",
    "    model = RANZCRStageZero(params)\n",
    "    model.nn_module.load_state_dict(state_dict)\n",
    "    model.set_device((0, 1, 2, 3))\n",
    "\n",
    "    train_dataset, val_dataset = Subset(dataset, train_index), Subset(dataset, test_index)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size, num_workers=config.n_workers, pin_memory=True, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.valid_batch_size, num_workers=config.n_workers, pin_memory=True)\n",
    "\n",
    "    callbacks = [\n",
    "        MonitorCheckpoint(dir_path=f'{config.experiment_name}_stage2_fold_{i}', monitor='val_multi_auc', max_saves=3),\n",
    "        CosineAnnealingLR(T_max=10, eta_min=config.min_lr),\n",
    "        LoggingToFile(f'{config.experiment_name}_stage2_fold_{i}.log'),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=10,\n",
    "        metrics=['loss', 'multi_auc'],\n",
    "        callbacks=callbacks,\n",
    "        metrics_on_train=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}